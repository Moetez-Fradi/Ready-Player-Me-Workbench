<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <title>RPM Viseme Player — Wolf3D_Head + Interviewer</title>
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <style>
    :root { --bg:#0b0c0d; --panel:#0f1316; --accent:#1f6feb; color-scheme: dark; }
    html,body{ overflow: hidden; height:100%; margin:0; background:var(--bg); font-family:Inter,system-ui,Segoe UI,Arial; color:#e6eef8; }
  </style>
  <script type="importmap">
  {
    "imports": {
      "three": "https://cdn.jsdelivr.net/npm/three@0.153.0/build/three.module.js",
      "three/addons/": "https://cdn.jsdelivr.net/npm/three@0.153.0/examples/jsm/"
    }
  }
  </script>
</head>
<body>
  <div id="sceneContainer" style="width:600px; height:400px; border:1px solid #555; margin:20px;">
    <canvas id="canvas"></canvas>
  </div>
  <div id="otherContent">
    <h1>Other stuff on the page</h1>
    <p>Buttons, text, whatever you want.</p>
  </div>

  <script type="module">
    import * as THREE from "three";
    import { OrbitControls } from "three/addons/controls/OrbitControls.js";
    import { GLTFLoader } from "three/addons/loaders/GLTFLoader.js";

    const canvas = document.getElementById('canvas');
    const renderer = new THREE.WebGLRenderer({ canvas, antialias: true });
    renderer.setPixelRatio(window.devicePixelRatio);
    renderer.localClippingEnabled = true;
    const scene = new THREE.Scene();
    scene.background = new THREE.Color(0x141619);
    const container = document.getElementById('sceneContainer');
    renderer.setSize(container.clientWidth, container.clientHeight);
    const camera = new THREE.PerspectiveCamera(40, container.clientWidth / container.clientHeight, 0.05, 200);
    camera.position.set(0, 1.6, 1.2);
    const controls = new OrbitControls(camera, renderer.domElement);
    controls.target.set(0, 1.6, 0);
    controls.enableRotate = false;
    controls.enableZoom = false;
    controls.enablePan = false;
    controls.update();
    const hemi = new THREE.HemisphereLight(0xffffff, 0x444444, 1.0);
    hemi.position.set(0, 1, 0);
    scene.add(hemi);
    const dir = new THREE.DirectionalLight(0xffffff, 1.0);
    dir.position.set(1,2,1);
    scene.add(dir);

    let model = null;
    let mixer = null;
    let clock = new THREE.Clock(false);
    let wolfMesh = null;
    let wolfDict = null;
    let morphInfluences = null;
    let headBone = null, spineBone = null, leftHandBone = null, rightHandBone = null;
    let running = false;
    const headState = { targetYaw:0, targetPitch:0, yaw:0, pitch:0, lerp:0.07 };
    const breathState = { t:0 };
    const handState = { left:{active:false, from:0, to:0, dur:0, t:0}, right:{active:false, from:0, to:0, dur:0, t:0} };
    let eyeBlinkTimer = 0;
    let visemeSequence = null;
    let visemeStartTime = 0;
    let visemePlaying = false;
    let visemeLoop = false;
    let visemeIndex = 0;
    let visemeTasks = [];
    let savedIdle = null;
    const loader = new GLTFLoader();
    const clipPlane = new THREE.Plane(new THREE.Vector3(0, 0, 0), -1.2);

    function r(min,max){ return min + Math.random() * (max - min); }
    function findHandBones(root){
      let left=null, right=null;
      root.traverse(o=>{
        if(!o.isBone) return;
        const n = (o.name||'').toLowerCase();
        if(!left && (n.includes('left') && (n.includes('hand') || n.includes('wrist') || n.includes('_l') || n.includes('.l')))) left = o;
        if(!right && (n.includes('right') && (n.includes('hand') || n.includes('wrist') || n.includes('_r') || n.includes('.r')))) right = o;
      });
      return {left,right};
    }

    function scheduleHeadTarget(){
      headState.targetYaw = r(-0.45, 0.45);
      headState.targetPitch = r(-0.12, 0.18);
      setTimeout(scheduleHeadTarget, r(1600, 3800));
    }
    function scheduleHandGesture(){
      const which = Math.random() < 0.6 ? 'right' : 'left';
      const s = handState[which];
      s.active = true;
      s.from = s.beg || 0;
      s.to = r(-0.8, 0.8);
      s.dur = r(280, 900);
      s.t = 0;
      s.beg = s.to;
      if(Math.random() < 0.18) setTimeout(scheduleHandGesture, r(140, 400));
      setTimeout(scheduleHandGesture, r(900, 3000));
    }

    function loadVisemeSequence(obj){
      if(!obj) return;
      if(Array.isArray(obj.events)){
        obj.events.sort((a,b)=>a.t - b.t);
        visemeSequence = obj;
      } else if(typeof obj.text === 'string'){
        const generated = generateVisemeEventsFromText(obj.text, obj.rate || 1.0);
        visemeSequence = { name: obj.name || 'generated_from_text', events: generated };
      }
    }
    function playVisemeSequence(loop=false){
      if(!visemeSequence) return;
      visemeLoop = loop;
      visemeIndex = 0;
      visemeTasks.length = 0;
      visemeStartTime = performance.now();
      visemePlaying = true;
    }
    function stopVisemePlayback(){
      visemePlaying = false;
    }

    function updateVisemePlayer(dt){
      if(visemePlaying && visemeSequence){
        const now = performance.now();
        const elapsed = now - visemeStartTime;
        while(visemeIndex < visemeSequence.events.length && visemeSequence.events[visemeIndex].t <= elapsed){
          const ev = visemeSequence.events[visemeIndex];
          visemeTasks.push({
            name: ev.v,
            intensity: typeof ev.i === 'number' ? Math.min(1, Math.max(0, ev.i)) : 1.0,
            timeLeft: typeof ev.d === 'number' ? ev.d : 140,
            decay: (typeof ev.decay === 'number') ? ev.decay : 0.02
          });
          visemeIndex++;
        }
        if(visemeIndex >= visemeSequence.events.length && visemePlaying){
          if(visemeLoop){
            visemeIndex = 0;
            visemeStartTime = performance.now();
          } else {
            visemePlaying = false;
          }
        }
      }
      if(wolfMesh && wolfDict){
        const influences = wolfMesh.morphTargetInfluences;
        for(let i=0;i<influences.length;i++){
          influences[i] = Math.max(0, influences[i] - 0.015 * dt * 60);
        }
        for(let i = visemeTasks.length - 1; i >= 0; i--){
          const t = visemeTasks[i];
          const idx = getMorphIndexForName(t.name);
          if(typeof idx === 'number'){
            influences[idx] = Math.max(influences[idx] || 0, t.intensity);
          }
          t.timeLeft -= dt * 1000;
          t.intensity = Math.max(0, t.intensity - t.decay * (dt * 60));
          if(t.timeLeft <= 0 || t.intensity <= 0.01) visemeTasks.splice(i,1);
        }
      }
    }
    function getMorphIndexForName(name){
      if(!wolfDict) return undefined;
      const lower = (name||'').toLowerCase();
      if(wolfDict[lower] !== undefined) return wolfDict[lower];
      const keys = Object.keys(wolfDict);
      for(const k of keys){ if(k.toLowerCase() === lower) return wolfDict[k]; }
      if(!lower.startsWith('viseme_') && wolfDict['viseme_' + lower] !== undefined) return wolfDict['viseme_' + lower];
      const alt = lower.replace(/[^a-z0-9]+/g,'');
      for(const k of keys){ if(k.toLowerCase().replace(/[^a-z0-9]+/g,'') === alt) return wolfDict[k]; }
      return undefined;
    }

    function updateHead(dt){
      if(!headBone) return;
      headState.yaw = THREE.MathUtils.lerp(headState.yaw, headState.targetYaw, headState.lerp);
      headState.pitch = THREE.MathUtils.lerp(headState.pitch, headState.targetPitch, headState.lerp);
      breathState.t += dt * 0.9;
      const bob = Math.sin(breathState.t * 0.9) * 0.015;
      if(spineBone) spineBone.rotation.x = bob;
      headBone.rotation.y = headState.yaw;
      headBone.rotation.x = headState.pitch;
    }
    function updateHands(dt){
      const apply = (bone, state)=>{
        if(!bone || !state) return;
        if(state.active){
          state.t += dt * 1000;
          const alpha = Math.min(1, state.t / state.dur);
          const eased = alpha*alpha*(3-2*alpha);
          const val = THREE.MathUtils.lerp(state.from, state.to, eased);
          bone.rotation.x = val;
          if(alpha >= 1) state.active = false;
        } else {
          bone.rotation.x = THREE.MathUtils.lerp(bone.rotation.x, 0, dt*2.4);
        }
      };
      apply(leftHandBone, handState.left);
      apply(rightHandBone, handState.right);
    }
    function updateEyesAndBlink(dt){
      eyeBlinkTimer -= dt * 1000;
      if(eyeBlinkTimer <= 0){
        eyeBlinkTimer = r(2200, 6500);
        const leftIdx = getMorphIndexForName('eyeBlinkLeft');
        const rightIdx = getMorphIndexForName('eyeBlinkRight');
        if(leftIdx !== undefined || rightIdx !== undefined){
          visemeTasks.push({ name: 'eyeBlinkLeft', intensity: 1.0, timeLeft: 120, decay: 0.03 });
          visemeTasks.push({ name: 'eyeBlinkRight', intensity: 1.0, timeLeft: 120, decay: 0.03 });
        }
      }
    }

    const letterMap = [
      {pattern: /th/ig, v: 'viseme_TH'},
      {pattern: /ch|tʃ|tch/ig, v: 'viseme_CH'},
      {pattern: /sh|ʃ/ig, v: 'viseme_SS'},
      {pattern: /f|v/ig, v: 'viseme_FF'},
      {pattern: /p|b|m/ig, v: 'viseme_PP'},
      {pattern: /k|g/ig, v: 'viseme_kk'},
      {pattern: /r/ig, v: 'viseme_RR'},
      {pattern: /n|ng/ig, v: 'viseme_nn'},
      {pattern: /ee|i|ie/ig, v: 'viseme_I'},
      {pattern: /ea|e(?![aiou])/ig, v: 'viseme_E'},
      {pattern: /ou|oo|u/ig, v: 'viseme_U'},
      {pattern: /o|au/ig, v: 'viseme_O'},
      {pattern: /a|aa|ah/ig, v: 'viseme_aa'}
    ];
    function generateVisemeEventsFromText(text, speed=1.0){
      text = (text||'').replace(/\s+/g,' ').trim();
      const tokens = [];
      const wordParts = text.split(/(\s+|[^\w'])/).filter(x=>x && !/\s+/.test(x));
      let t = 0;
      const baseDur = 120 / speed;
      for(const part of wordParts){
        let matched = false;
        for(const m of letterMap){
          const re = new RegExp(m.pattern);
          if(re.test(part)){
            const matches = [...part.matchAll(m.pattern)];
            for(const mm of matches){
              const dur = baseDur * (1 + Math.random()*0.5);
              tokens.push({t: Math.round(t), v: m.v, i: 0.85 - Math.random()*0.25, d: Math.round(dur)});
              t += dur * 0.7;
            }
            matched = true;
          }
        }
        if(!matched){
          const dur = baseDur * (0.6 + Math.random()*0.6);
          tokens.push({t: Math.round(t), v: 'jawOpen', i: 0.5 + Math.random()*0.35, d: Math.round(dur)});
          t += dur * 0.9;
        }
        t += baseDur * 0.45;
      }
      tokens.push({t: Math.round(t + 40), v: 'viseme_sil', i: 0, d: 120});
      return tokens;
    }

    const predefinedAnimations = {
      'hemmm': [
        { t: 0, v: 'viseme_PP', i: 0.8, d: 200 },
        { t: 150, v: 'viseme_PP', i: 0.6, d: 150 },
        { t: 0, v: 'browInnerUp', i: 0.7, d: 350 },
        { t: 100, v: 'eyeLookOutLeft', i: 0.5, d: 250 },
        { t: 200, v: 'eyeLookOutRight', i: 0.5, d: 250 }
      ]
    };
    function getSequenceDuration(seq) {
      if (!seq.length) return 0;
      const last = seq.reduce((max, ev) => ev.t > max.t ? ev : max, seq[0]);
      return last.t + last.d;
    }
    let synthUtterance = null;
    function speakTextWithVisemes(text, options={}) {
      if(!text) return;
      const useVoice = true;
      const interruptIdle = true;
      let cleanText = '';
      let cumulativeT = 0;
      let allEvents = [];
      const parts = text.split(/(\[.*?\])/g);
      for (const part of parts) {
        if (part.startsWith('[') && part.endsWith(']')) {
          const action = part.slice(1, -1).trim().toLowerCase();
          if (predefinedAnimations[action]) {
            const seq = predefinedAnimations[action].map(ev => ({ ...ev, t: ev.t + cumulativeT }));
            allEvents.push(...seq);
            cumulativeT += getSequenceDuration(predefinedAnimations[action]);
          }
        } else {
          cleanText += part;
          const events = generateVisemeEventsFromText(part, options.rate || 1.0);
          const shifted = events.map(ev => ({ ...ev, t: ev.t + cumulativeT }));
          allEvents.push(...shifted);
          cumulativeT += getSequenceDuration(events);
        }
      }
      const seq = { name: 'speech_gen', events: allEvents };
      if(interruptIdle && visemeSequence === null){ savedIdle = {visemeSequence:null}; }
      visemeSequence = seq;
      playVisemeSequence(false);
      if(useVoice && 'speechSynthesis' in window){
        try {
          window.speechSynthesis.cancel();
          synthUtterance = new SpeechSynthesisUtterance(cleanText);
          synthUtterance.rate = options.rate || 1.0;
          synthUtterance.pitch = options.pitch || 1.0;
          synthUtterance.onstart = () => { console.log('TTS started'); }
          synthUtterance.onend = () => {
            setTimeout(()=>{ visemePlaying = false; visemeSequence = null; visemeTasks.length = 0; }, 120);
          }
          window.speechSynthesis.speak(synthUtterance);
        } catch (e) {
          console.warn('TTS call failed', e);
        }
      } else {
        visemeStartTime = performance.now();
        visemePlaying = true;
        setTimeout(()=>{ visemePlaying = false; visemeSequence = null; visemeTasks.length = 0; console.log('Simulated speech finished'); }, Math.max(800, allEvents[allEvents.length-1].t + allEvents[allEvents.length-1].d + 60));
      }
    }
    function stopSpeech(){
      if(synthUtterance) window.speechSynthesis.cancel();
      visemePlaying = false;
      visemeSequence = null;
      visemeTasks.length = 0;
    }

    function animate(){
      if(!running) return;
      requestAnimationFrame(animate);
      const dt = clock.getDelta();
      if(mixer) mixer.update(dt);
      updateHead(dt);
      updateHands(dt);
      updateEyesAndBlink(dt);
      updateVisemePlayer(dt);
      renderer.render(scene, camera);
    }

    function clearModel(){
      if(model) {
        scene.remove(model);
        model.traverse(o=>{
          if(o.geometry) o.geometry.dispose();
          if(o.material){ if(Array.isArray(o.material)) o.material.forEach(m=>m.dispose()); else o.material.dispose(); }
        });
      }
      model = null; mixer = null; wolfMesh = null; wolfDict = null; morphInfluences = null;
      headBone = spineBone = leftHandBone = rightHandBone = null;
    }
    function onModelLoaded(gltf){
      clearModel();
      model = gltf.scene;
      model.traverse(obj => {
        if (obj.isMesh && obj.material) {
          if (Array.isArray(obj.material)) {
            obj.material.forEach(mat => { mat.clippingPlanes = [clipPlane]; mat.needsUpdate = true; });
          } else {
            obj.material.clippingPlanes = [clipPlane];
            obj.material.needsUpdate = true;
          }
        }
      });
      scene.add(model);
      model.traverse(obj=>{
        if(obj.isMesh){
          const name = (obj.name||'').toLowerCase();
          if(name.includes('wolf3d_head') || name.includes('wolf3d_headmesh') || name.includes('wolf3d_head ')){
            wolfMesh = obj;
            const d = {};
            for(const k in (obj.morphTargetDictionary || {})) d[k] = obj.morphTargetDictionary[k];
            wolfDict = d;
            morphInfluences = obj.morphTargetInfluences;
            console.log('Detected Wolf3D_Head mesh with ' + Object.keys(wolfDict).length + ' morphs.');
          }
        }
        if(!headBone && obj.isBone){
          const n = (obj.name||'').toLowerCase();
          if(n.includes('head') || n.includes('neck')) headBone = obj;
          if(n.includes('spine') && !spineBone) spineBone = obj;
        }
      });
      if(!wolfMesh){
        model.traverse(obj=>{
          if(!wolfMesh && obj.isMesh && obj.morphTargetDictionary){
            const keys = Object.keys(obj.morphTargetDictionary).map(s=>s.toLowerCase());
            if(keys.some(k => k.startsWith('viseme') || k.includes('jaw') || k.includes('mouth'))){
              wolfMesh = obj;
              wolfDict = Object.assign({}, obj.morphTargetDictionary);
              morphInfluences = obj.morphTargetInfluences;
              console.log('Using mesh "' + obj.name + '" as viseme target (detected viseme-like morphs).');
            }
          }
        });
      }
      const hands = findHandBones(model);
      leftHandBone = hands.left;
      rightHandBone = hands.right;
      console.log('Head bone: ' + (headBone ? headBone.name : 'none') + ' | Left hand: ' + (leftHandBone ? leftHandBone.name : 'none') + ' | Right hand: ' + (rightHandBone ? rightHandBone.name : 'none'));
      if(gltf.animations && gltf.animations.length){
        mixer = new THREE.AnimationMixer(model);
        try { const action = mixer.clipAction(gltf.animations[0]); action.play(); } catch(e){}
      }
      scheduleHeadTarget();
      clock.start();
      running = true;
      animate();
      fetch('./speech.json')
        .then(res => res.json())
        .then(obj => {
          if (obj.text) {
            speakTextWithVisemes(obj.text, { rate: obj.rate || 1.0 });
          } else {
            console.log('No text in speech.json');
          }
        })
        .catch(err => console.error('Error loading speech.json:', err));
    }

    loader.load('./char.glb', onModelLoaded, undefined, err => {
      console.error('GLB load error:', err);
    });

    window.addEventListener('resize', ()=>{
      renderer.setSize(container.clientWidth, container.clientHeight);
      camera.aspect = container.clientWidth / container.clientHeight;
      camera.updateProjectionMatrix();
    });
    window.__rpmVisemeDebug = () => ({ model, wolfMesh, wolfDict, visemeSequence, visemeTasks });
    console.log('Ready. Loading char.glb and speech.json automatically.');
    running = true;
    clock.start();
    animate();

    // ---------------- Voice UI + Recorder + WS integration ----------------
    (() => {
      const ui = document.createElement('div');
      ui.style = 'position:fixed;right:18px;bottom:18px;z-index:9999;background:rgba(10,12,14,0.85);color:#ddd;padding:10px;border-radius:8px;font-family:Inter,system-ui,Arial;';
      ui.innerHTML = `
        <div style="font-size:13px;margin-bottom:6px">Voice — record & send</div>
        <button id="recBtn">● Record</button>
        <button id="stopBtn" disabled>■ Stop</button>
        <div id="voiceStatus" style="margin-top:6px;font-size:12px;opacity:0.9"></div>
        <div id="queueInfo" style="margin-top:8px;font-size:12px;opacity:0.85">Queue: 0</div>
      `;
      document.body.appendChild(ui);
      const recBtn = ui.querySelector('#recBtn');
      const stopBtn = ui.querySelector('#stopBtn');
      const voiceStatus = ui.querySelector('#voiceStatus');
      const queueInfo = ui.querySelector('#queueInfo');

      const proto = location.protocol === 'https:' ? 'wss:' : 'ws:';
      const wsUrl = 'http://localhost:8080/ws/voice';
      const ws = new WebSocket(wsUrl);
      ws.binaryType = 'arraybuffer';

      ws.addEventListener('open', () => { console.log('Voice WS connected'); voiceStatus.textContent = 'WS connected'; });
      ws.addEventListener('close', () => { console.log('Voice WS closed'); voiceStatus.textContent = 'WS closed'; });
      ws.addEventListener('error', (e) => { console.error('WS error', e); voiceStatus.textContent = 'WS error'; });

      let audioCtx = null;
      let mediaStream = null;
      let processor = null;
      let sourceNode = null;
      let zeroGain = null;
      let recordedBuffers = [];
      let recording = false;
      let originalSampleRate = 48000;

      function mergeBuffers(buffers) {
        let totalLen = buffers.reduce((s, b) => s + b.length, 0);
        if (totalLen === 0) return new Float32Array(0);
        const out = new Float32Array(totalLen);
        let offset = 0;
        for (let i = 0; i < buffers.length; i++) {
          out.set(buffers[i], offset);
          offset += buffers[i].length;
        }
        return out;
      }

      async function resampleFloat32Buffer(float32Samples, inSampleRate, outSampleRate) {
        if (!float32Samples || float32Samples.length === 0) return new Float32Array(0);
        if (inSampleRate === outSampleRate) return float32Samples;
        const lengthInSec = float32Samples.length / inSampleRate;
        const targetLength = Math.ceil(lengthInSec * outSampleRate) || 1;
        const offlineCtx = new OfflineAudioContext(1, targetLength, outSampleRate);
        const buffer = offlineCtx.createBuffer(1, float32Samples.length, inSampleRate);
        buffer.copyToChannel(float32Samples, 0, 0);
        const src = offlineCtx.createBufferSource();
        src.buffer = buffer;
        src.connect(offlineCtx.destination);
        src.start(0);
        const rendered = await offlineCtx.startRendering();
        return rendered.getChannelData(0);
      }

      function floatTo16BitPCM(view, offset, input) {
        for (let i = 0; i < input.length; i++, offset += 2) {
          let s = Math.max(-1, Math.min(1, input[i]));
          s = s < 0 ? s * 0x8000 : s * 0x7fff;
          view.setInt16(offset, s, true);
        }
      }
      function writeString(view, offset, string) {
        for (let i = 0; i < string.length; i++) {
          view.setUint8(offset + i, string.charCodeAt(i));
        }
      }

      function encodeWAVFromFloat32(float32Samples, sampleRate) {
        const numChannels = 1;
        const bytesPerSample = 2;
        const blockAlign = numChannels * bytesPerSample;
        const byteRate = sampleRate * blockAlign;
        const dataLength = (float32Samples ? float32Samples.length : 0) * bytesPerSample;
        const buffer = new ArrayBuffer(44 + dataLength);
        const view = new DataView(buffer);
        writeString(view, 0, 'RIFF');
        view.setUint32(4, 36 + dataLength, true);
        writeString(view, 8, 'WAVE');
        writeString(view, 12, 'fmt ');
        view.setUint32(16, 16, true);
        view.setUint16(20, 1, true);
        view.setUint16(22, numChannels, true);
        view.setUint32(24, sampleRate, true);
        view.setUint32(28, byteRate, true);
        view.setUint16(32, blockAlign, true);
        view.setUint16(34, bytesPerSample * 8, true);
        writeString(view, 36, 'data');
        view.setUint32(40, dataLength, true);
        if (float32Samples && float32Samples.length > 0) floatTo16BitPCM(view, 44, float32Samples);
        return buffer;
      }

      async function startRecording() {
        if (recording) return;
        try {
          if (!audioCtx) {
            audioCtx = new (window.AudioContext || window.webkitAudioContext)();
            originalSampleRate = audioCtx.sampleRate || 48000;
          }
          if (audioCtx.state === 'suspended') await audioCtx.resume();
          mediaStream = await navigator.mediaDevices.getUserMedia({ audio: true });
          sourceNode = audioCtx.createMediaStreamSource(mediaStream);
          processor = audioCtx.createScriptProcessor(4096, 1, 1);
          recordedBuffers = [];
          processor.onaudioprocess = e => {
            const ch = e.inputBuffer.getChannelData(0);
            recordedBuffers.push(new Float32Array(ch));
          };
          zeroGain = audioCtx.createGain();
          zeroGain.gain.value = 0;
          sourceNode.connect(processor);
          processor.connect(zeroGain);
          zeroGain.connect(audioCtx.destination);
          recording = true;
          recBtn.disabled = true;
          stopBtn.disabled = false;
          voiceStatus.textContent = 'Recording…';
        } catch (err) {
          console.error('mic err', err);
          voiceStatus.textContent = 'Microphone error: ' + (err.message || err);
        }
      }

      async function stopRecordingAndSend() {
        if (!recording) return;
        if (processor) { processor.disconnect(); processor.onaudioprocess = null; processor = null; }
        if (sourceNode) { try{ sourceNode.disconnect(); } catch(e){} sourceNode = null; }
        if (zeroGain) { try{ zeroGain.disconnect(); } catch(e){} zeroGain = null; }
        if (mediaStream) {
          mediaStream.getTracks().forEach(t => t.stop());
          mediaStream = null;
        }
        recording = false;
        recBtn.disabled = false;
        stopBtn.disabled = true;
        voiceStatus.textContent = 'Encoding…';

        try {
          const merged = mergeBuffers(recordedBuffers);
          if (!merged || merged.length === 0) {
            voiceStatus.textContent = 'No audio recorded (silent or permission denied)';
            console.warn('No audio data to send.');
            return;
          }
          const targetRate = 22050;
          const resampled = await resampleFloat32Buffer(merged, originalSampleRate, targetRate);
          const wavBuffer = encodeWAVFromFloat32(resampled, targetRate);
          if (ws && ws.readyState === WebSocket.OPEN) {
            ws.send(wavBuffer);
            voiceStatus.textContent = 'Sent to backend';
          } else {
            voiceStatus.textContent = 'WS not open';
          }
        } catch (err) {
          console.error('encoding/send err', err);
          voiceStatus.textContent = 'Encode/send error: ' + (err.message || err);
        }
      }

      recBtn.addEventListener('click', startRecording);
      stopBtn.addEventListener('click', stopRecordingAndSend);

      const playQueue = [];
      let playing = false;

      function updateQueueInfo() {
        queueInfo.textContent = `Queue: ${playQueue.length}${playing ? ' (playing)' : ''}`;
      }

      function base64ToArrayBuffer(base64) {
        const binary = atob(base64);
        const len = binary.length;
        const bytes = new Uint8Array(len);
        for (let i = 0; i < len; i++) bytes[i] = binary.charCodeAt(i);
        return bytes.buffer;
      }

      function convertLipsyncToEvents(lipsync, fallbackText) {
        try {
          if (!lipsync) {
            return { events: generateVisemeEventsFromText(fallbackText || '', 1.0) };
          }
          if (Array.isArray(lipsync)) {
            const events = lipsync.map(c => {
              const start = (c.start ?? c.t ?? 0) * 1000;
              const end = (c.end ?? (c.start + (c.d ?? 0)) ?? start / 1000) * 1000;
              const name = (c.value || c.v || c.name || '').toString();
              return { t: Math.round(start), v: normalizeVisemeName(name), i: 1.0, d: Math.max(20, Math.round(end - start)) };
            });
            return { events };
          }
          if (lipsync.mouthCues && Array.isArray(lipsync.mouthCues)) {
            const events = lipsync.mouthCues.map(c => {
              const start = (c.start ?? 0) * 1000;
              const end = (c.end ?? (c.start + 0.08)) * 1000;
              const name = (c.value || c.viseme || c.label || '').toString();
              return { t: Math.round(start), v: normalizeVisemeName(name), i: 1.0, d: Math.max(20, Math.round(end - start)) };
            });
            return { events };
          }
          if (lipsync.cues && Array.isArray(lipsync.cues)) {
            return convertLipsyncToEvents(lipsync.cues.map(c => ({ start: c.s || c.start, end: c.e || c.end, value: c.v || c.value })));
          }
          if (lipsync.phonemes && Array.isArray(lipsync.phonemes)) {
            const events = lipsync.phonemes.map(p => {
              const start = (p.start ?? 0) * 1000;
              const dur = (p.duration ?? 0.08) * 1000;
              return { t: Math.round(start), v: normalizeVisemeName(p.symbol || p.viseme || p.value || 'viseme_sil'), i: 1.0, d: Math.round(dur) };
            });
            return { events };
          }
          return { events: generateVisemeEventsFromText(fallbackText || '', 1.0) };
        } catch (e) {
          console.warn('lipsync conversion failed', e);
          return { events: generateVisemeEventsFromText(fallbackText || '', 1.0) };
        }
      }

      function normalizeVisemeName(name) {
        if (!name) return 'viseme_sil';
        const s = name.toString().trim();
        if (/^viseme_/i.test(s)) return s;
        const map = {
          'PP': 'viseme_PP', 'FF': 'viseme_FF', 'TH': 'viseme_TH', 'CH': 'viseme_CH', 'SS':'viseme_SS',
          'kk':'viseme_kk','KK':'viseme_kk','AA':'viseme_aa','I':'viseme_I','E':'viseme_E','U':'viseme_U','O':'viseme_O'
        };
        if (map[s]) return map[s];
        const lower = s.toLowerCase();
        if (/pp|p|b|m/.test(lower)) return 'viseme_PP';
        if (/f|v/.test(lower)) return 'viseme_FF';
        if (/th/.test(lower)) return 'viseme_TH';
        if (/ch/.test(lower)) return 'viseme_CH';
        if (/s|sh/.test(lower)) return 'viseme_SS';
        return 'viseme_' + s.replace(/[^a-z0-9]+/ig, '');
      }

      async function enqueueIncomingSpeech(obj) {
        if (!obj) return;
        if (!obj.audio) {
          const seq = convertLipsyncToEvents(obj.lipsync, obj.text);
          playQueue.push({ audioBuffer: null, lipsyncEvents: seq.events, text: obj.text });
          updateQueueInfo();
          if (!playing) playNextFromQueue();
          return;
        }
        try {
          const ab = base64ToArrayBuffer(obj.audio);
          const audioBuf = await (async () => {
            if (!audioCtx) audioCtx = new (window.AudioContext || window.webkitAudioContext)();
            return await audioCtx.decodeAudioData(ab.slice(0));
          })();
          const seq = convertLipsyncToEvents(obj.lipsync, obj.text);
          playQueue.push({ audioBuffer: audioBuf, lipsyncEvents: seq.events, text: obj.text });
          updateQueueInfo();
          if (!playing) playNextFromQueue();
        } catch (e) {
          console.error('decode audio err', e);
          const seq = convertLipsyncToEvents(obj.lipsync, obj.text);
          playQueue.push({ audioBuffer: null, lipsyncEvents: seq.events, text: obj.text });
          updateQueueInfo();
          if (!playing) playNextFromQueue();
        }
      }

      function scheduleVisemeSequenceForPlayback(events, startDelayMs = 0) {
        const seq = { name: 'remote_speech', events: events.map(ev => ({ t: Math.round(ev.t + startDelayMs), v: ev.v, i: (ev.i ?? 1.0), d: ev.d })) };
        loadVisemeSequence(seq);
        playVisemeSequence(false);
      }

      async function playNextFromQueue() {
        if (playQueue.length === 0) {
          playing = false;
          updateQueueInfo();
          return;
        }
        playing = true;
        updateQueueInfo();
        const item = playQueue.shift();
        updateQueueInfo();

        if (item.audioBuffer) {
          if (audioCtx && audioCtx.state === 'suspended') await audioCtx.resume();
          const src = audioCtx.createBufferSource();
          src.buffer = item.audioBuffer;
          src.connect(audioCtx.destination);
          const startInSec = 0.05;
          const startTime = audioCtx.currentTime + startInSec;
          const msUntilStart = startInSec * 1000;
          const events = item.lipsyncEvents || [];
          loadVisemeSequence({ events });
          src.start(startTime);
          setTimeout(() => { playVisemeSequence(false); }, msUntilStart);
          src.onended = () => {
            setTimeout(() => {
              visemePlaying = false;
              visemeSequence = null;
              visemeTasks.length = 0;
              playing = false;
              playNextFromQueue();
            }, 80);
          };
        } else {
          loadVisemeSequence({ events: item.lipsyncEvents || generateVisemeEventsFromText(item.text || '') });
          const last = (visemeSequence && visemeSequence.events && visemeSequence.events.length) ? visemeSequence.events[visemeSequence.events.length - 1] : null;
          const totalMs = last ? (last.t + (last.d || 140) + 60) : 800;
          playVisemeSequence(false);
          setTimeout(() => {
            visemePlaying = false;
            visemeSequence = null;
            visemeTasks.length = 0;
            playing = false;
            playNextFromQueue();
          }, totalMs);
        }
      }

      ws.addEventListener('message', async (ev) => {
        try {
          if (typeof ev.data === 'string') {
            let parsed = null;
            try { parsed = JSON.parse(ev.data); } catch (e) { console.log('WS text:', ev.data); return; }
            const t = parsed.type || 'response';
            if (t === 'persona' || t === 'opening' || t === 'response' || t === 'response_start' || t === 'audio_chunk' || t === 'response_end') {
              await enqueueIncomingSpeech(parsed);
            } else {
              console.log('WS message:', parsed);
            }
          } else {
            console.log('Received non-text ws message (binary) — ignoring');
          }
        } catch (err) {
          console.error('ws msg err', err);
        }
      });

      window.addEventListener('beforeunload', () => {
        if (mediaStream) mediaStream.getTracks().forEach(t => t.stop());
        try { ws.close(); } catch (e) {}
      });

      window.__voiceWS = { ws, enqueueIncomingSpeech, playQueue };

    })();
  </script>
</body>
</html>
